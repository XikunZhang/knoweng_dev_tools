{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Data Cleanup and Samples Clustering using make and the *.yml files in the run_dir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         load python library code\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "import knpackage.toolbox as kn\n",
    "\n",
    "sys.path.insert(1, '../../Data_Cleanup_Pipeline/src')\n",
    "import data_cleanup_toolbox as dc\n",
    "\n",
    "sys.path.insert(1, '../../Samples_Clustering_Pipeline/src')\n",
    "import sample_clustering_toolbox as sc\n",
    "\n",
    "sys.path.insert(1, '../src')\n",
    "# import pyverify as pyvif\n",
    "import KnowEnG_graphics as gu\n",
    "import run_file_utility as rfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                   \"activate\" a yaml file (guard against path name madness)\n",
    "run_dir = '../test/run_dir'\n",
    "base_path = os.path.abspath('../../')\n",
    "notebook_run_file = os.path.join(base_path, 'keg_test_tools/data/run_files/samples_clustering_4_notebook.yml')\n",
    "run_file_name = rfu.set_run_file_path_to_abs(notebook_run_file, run_dir)\n",
    "print('Run File Name set to:', run_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                   Run Data Cleaning\n",
    "%run ../../Data_Cleanup_Pipeline/src/data_cleanup.py -run_directory ../test/run_dir -run_file samples_clustering_4_notebook_Active.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                   Update the run file\n",
    "STATUS = rfu.update_run_file_post_clean(run_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                   Run Samples Clustering\n",
    "%run ../../Samples_Clustering_Pipeline/src/data_cleanup.py -run_directory ../test/run_dir -run_file samples_clustering_4_notebook_Active.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                   Test the Run Command\n",
    "%run ../src/clustersay.py -file_name ../../Samples_Clustering_Pipeline/data/verification/UCEC_ST90Q_result_precalc.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                                 module code verification cell\n",
    "run_dir = '../test/run_dir'\n",
    "base_path = os.path.abspath('../../')\n",
    "notebook_run_file = os.path.join(base_path, 'keg_test_tools/data/run_files/samples_clustering_4_notebook.yml')\n",
    "run_file_name = rfu.set_run_file_path_to_abs(notebook_run_file, run_dir)\n",
    "print(run_file_name, 'exists?',os.path.isfile(run_file_name))\n",
    "STATUS = rfu.update_run_file_post_clean(run_file_name)\n",
    "print(run_file_name, 'Updated?', STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lanier4/dlanier_KnowEnG/Data_Cleanup_Pipeline/test\n"
     ]
    }
   ],
   "source": [
    "#         Set the run file names\n",
    "DC_run_dir_name = '../../Data_Cleanup_Pipeline/test/run_dir'\n",
    "DC_run_file_name = 'data_cleanup.yml'\n",
    "Data_Cleanup_Run_File = os.path.abspath(os.path.join(DC_run_dir_name, DC_run_file_name))\n",
    "\n",
    "SC_run_dir_name = '../../Samples_Clustering_Pipeline/test/run_dir'\n",
    "SC_run_file_name = 'BENCHMARK_7_SC_cc_net_nmf_parallel_shared.yml'\n",
    "Samples_Clustering_Run_File = os.path.abspath(os.path.join(SC_run_dir_name, SC_run_file_name))\n",
    "\n",
    "#         Set the Data Cleaning run time environment\n",
    "%cd ../../Data_Cleanup_Pipeline/test \n",
    "# %system make final_clean\n",
    "# %system make env_setup\n",
    "\n",
    "pyvif.set_results_directory(Data_Cleanup_Run_File)\n",
    "\n",
    "#         Set the spreadsheet and phenotype file names\n",
    "spreadsheet_file_path = os.path.abspath('../../Samples_Clustering_Pipeline/data/spreadsheets')\n",
    "spreadsheet_file_name = os.path.join(spreadsheet_file_path, 'tcga_ucec_somatic_mutation_data.df')\n",
    "pyvif.set_spreadsheet_name(Data_Cleanup_Run_File, spreadsheet_file_name)\n",
    "\n",
    "phenotype_file_path = os.path.abspath('../../Samples_Clustering_Pipeline/data/spreadsheets')\n",
    "phenotype_file_name = os.path.join(phenotype_file_path, 'UCEC_phenotype.txt')\n",
    "pyvif.set_phenotype_name(Data_Cleanup_Run_File, phenotype_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Clustering Cleanup run time: 935.8642239570618\n"
     ]
    }
   ],
   "source": [
    "#           Run Data Cleaning for Samples Clustering\n",
    "\n",
    "t0 = time.time()\n",
    "%system make run_data_cleaning\n",
    "print('Samples Clustering Cleanup run time:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lanier4/dlanier_KnowEnG/Samples_Clustering_Pipeline/test\n",
      "/Users/lanier4/dlanier_KnowEnG/Samples_Clustering_Pipeline/test/run_dir/results \n",
      " True\n",
      "/Users/lanier4/dlanier_KnowEnG/Samples_Clustering_Pipeline/data/networks/keg_ST90_4col.edge \n",
      " True\n",
      "Samples Clustering cc net nmf run time: 1.265078067779541\n"
     ]
    }
   ],
   "source": [
    "#         Set up and Run Samples Clustering with data Cleaning results\n",
    "%cd ../../Samples_Clustering_Pipeline/test\n",
    "%system make clean_dir_recursively\n",
    "%system make env_setup\n",
    "\n",
    "pyvif.set_results_directory(Samples_Clustering_Run_File, os.path.join(SC_run_dir_name, 'results'))\n",
    "pyvif.update_SC_run_file(Data_Cleanup_Run_File, Samples_Clustering_Run_File)\n",
    "\n",
    "results_dir_tmp = pyvif.get_results_directory(Samples_Clustering_Run_File)\n",
    "print(results_dir_tmp,'\\n',os.path.isdir(results_dir_tmp))\n",
    "\n",
    "nw_name = pyvif.get_gg_network_name(Samples_Clustering_Run_File)\n",
    "pyvif.write_yaml_key_file_name(Samples_Clustering_Run_File, nw_name, 'gg_network_name_full_path')\n",
    "nw_name = pyvif.get_gg_network_name(Samples_Clustering_Run_File)\n",
    "print(nw_name,'\\n',os.path.isfile(nw_name))\n",
    "\n",
    "t0 = time.time()\n",
    "%system make run_cc_net_nmf_parallel_shared\n",
    "print('Samples Clustering cc net nmf run time:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('/Users/lanier4/dlanier_KnowEnG/Data_Cleanup_Pipeline/test/run_dir/results/UCEC_phenotype_ETL.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('/Users/lanier4/dlanier_KnowEnG/Data_Cleanup_Pipeline/test/run_dir/results/UCEC_phenotype_ETL.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation_measure                     : pearson\n",
      "phenotype_name_full_path                : /Users/lanier4/dlanier_KnowEnG/Samples_Clustering_Pipeline/data/spreadsheets/UCEC_phenotype.txt\n",
      "pipeline_type                           : gene_prioritization_pipeline\n",
      "redis_credential                        : {'password': 'KnowEnG', 'host': 'knowredis.knowhub.org', 'port': 6379}\n",
      "results_directory                       : /Users/lanier4/dlanier_KnowEnG/Data_Cleanup_Pipeline/test/run_dir/results\n",
      "source_hint                             : \n",
      "spreadsheet_name_full_path              : /Users/lanier4/dlanier_KnowEnG/Samples_Clustering_Pipeline/data/spreadsheets/tcga_ucec_somatic_mutation_data.df\n",
      "taxonid                                 : 9606\n"
     ]
    }
   ],
   "source": [
    "pyvif.print_out_the_yml_file(Data_Cleanup_Run_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_sampling_fraction                  : 0.8\n",
      "gg_network_name_full_path               : ../data/networks/keg_ST90_4col.edge\n",
      "method                                  : cc_net_nmf\n",
      "nmf_conv_check_freq                     : 50\n",
      "nmf_max_invariance                      : 200\n",
      "nmf_max_iterations                      : 10000\n",
      "nmf_penalty_parameter                   : 1400\n",
      "number_of_bootstraps                    : 4\n",
      "number_of_clusters                      : 3\n",
      "parallelism                             : 4\n",
      "phenotype_name_full_path                : /Users/lanier4/dlanier_KnowEnG/Data_Cleanup_Pipeline/test/run_dir/results/UCEC_phenotype_ETL.tsv\n",
      "processing_method                       : parallel\n",
      "results_directory                       : /Users/lanier4/dlanier_KnowEnG/Samples_Clustering_Pipeline/test/run_dir/results\n",
      "rows_sampling_fraction                  : 0.8\n",
      "rwr_convergence_tolerence               : 0.0001\n",
      "rwr_max_iterations                      : 100\n",
      "rwr_restart_probability                 : 0.7\n",
      "spreadsheet_name_full_path              : /Users/lanier4/dlanier_KnowEnG/Data_Cleanup_Pipeline/test/run_dir/results/UCEC_phenotype_ETL.tsv\n",
      "threshold                               : 10\n",
      "tmp_directory                           : ./run_dir/tmp\n",
      "top_number_of_genes                     : 100\n"
     ]
    }
   ],
   "source": [
    "pyvif.print_out_the_yml_file(Samples_Clustering_Run_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_Cleanup_methods_dictionary =               {\n",
    "    'run_data_cleaning'                         : 'data_cleanup.yml',\n",
    "    'run_pasted_gene_list'                      : 'pasted_gene_cleanup.yml',\n",
    "    'run_data_cleaning_small'                   : 'TEST_1_data_cleanup.yml',\n",
    "    'run_samples_clustering_pipeline'           : 'TEST_1_samples_clustering_pipeline.yml',\n",
    "    'run_gene_prioritization_pipeline_pearson'  : 'TEST_1_gene_prioritization_pipeline_pearson.yml',\n",
    "    'run_gene_prioritization_pipeline_t_test'   : 'TEST_1_gene_prioritization_pipeline_t_test.yml',\n",
    "    'run_geneset_characterization_pipeline'     : 'TEST_1_geneset_characterization_pipeline.yml' }\n",
    "\n",
    "Samples_Clustering_methods_dictionary = {\n",
    "    'run_nmf'                           : 'BENCHMARK_1_SC_nmf.yml',\n",
    "    'run_net_nmf'                       : 'BENCHMARK_2_SC_net_nmf.yml',\n",
    "    'run_cc_nmf_serial'                 : 'BENCHMARK_3_SC_cc_nmf_serial.yml',\n",
    "    'run_cc_nmf_parallel_shared'        : 'BENCHMARK_4_SC_cc_nmf_parallel_shared.yml',\n",
    "    'run_cc_net_nmf_serial'             : 'BENCHMARK_6_SC_cc_net_nmf_serial.yml',\n",
    "    'run_cc_net_nmf_parallel_shared'    : 'BENCHMARK_7_SC_cc_net_nmf_parallel_shared.yml' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results_directory = pyvif.get_results_directory(Samples_Clustering_Run_File)\n",
    "results_dir_list = os.listdir(results_directory)\n",
    "cc_5mat = None\n",
    "cc_prefix = 'consensus_matrix'\n",
    "cluster_evaluation_prefix = 'clustering_evaluation_result'\n",
    "cluster_eval_df = None\n",
    "for l in results_dir_list:\n",
    "    if l[0:len(cc_prefix)] == cc_prefix:\n",
    "        consensus_matrix_file = os.path.join(samples_clustering_pars['results_directory'], l)\n",
    "        consensus_df = pd.read_csv(consensus_matrix_file, sep='\\t', header=0, index_col=0)\n",
    "        cc_5mat = consensus_df.as_matrix()\n",
    "    if l[0:len(cluster_evaluation_prefix)] == cluster_evaluation_prefix:\n",
    "        cluster_eval_filename = os.path.join(samples_clustering_pars['results_directory'], l)\n",
    "        cluster_eval_df = pd.read_csv(cluster_eval_filename, sep='\\t', header=0, index_col=0)\n",
    "\n",
    "Maximum_Consensus_Matrix_Display_Width = 1200\n",
    "if cc_5mat is not None and cc_5mat.shape[1] < Maximum_Consensus_Matrix_Display_Width:\n",
    "    I0 = sc.form_consensus_matrix_graphic(cc_5mat, samples_clustering_pars[ 'number_of_clusters' ])\n",
    "    display(gu.mat_to_blue(I0))\n",
    "    \n",
    "if cluster_eval_df is not None:\n",
    "    display(cluster_eval_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
