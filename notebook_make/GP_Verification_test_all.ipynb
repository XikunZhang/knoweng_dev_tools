{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this notebook to confirm that changes to Gene Prioritization Pipeline code did not change the outupt.\n",
    "* after running notebook use  \"File\" > \"Download as\"  >  (html) to save test results.\n",
    "\n",
    "###### Be advised: running this notebook in the same directory at the same time as the script will eat the temporary directories and fail tests.\n",
    "* And display _**disparaging error messages**_ on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <- must be == In [1]  only run this cell first (or) after restarting kernel\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import knpackage.toolbox as kn\n",
    "\n",
    "sys.path.insert(1, '../verification')\n",
    "import verification_test as vt\n",
    "run_dir = os.path.abspath('../')\n",
    "\n",
    "t_start_test = time.time()\n",
    "sum_of_all_differences = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_bootstrap_net_pearson               : BENCHMARK_4_GP_bootstrap_net_pearson\n",
      "run_bootstrap_net_t_test                : BENCHMARK_8_GP_bootstrap_net_t_test\n",
      "run_bootstrap_pearson                   : BENCHMARK_2_GP_bootstrap_pearson\n",
      "run_bootstrap_t_test                    : BENCHMARK_6_GP_bootstrap_t_test\n",
      "run_multidrug_pearson                   : TEST_2_GP_many_drugs_pearson\n",
      "run_multidrug_t_test                    : TEST_4_GP_many_drugs_t_test\n",
      "run_net_pearson                         : BENCHMARK_3_GP_net_pearson\n",
      "run_net_t_test                          : BENCHMARK_7_GP_net_t_test\n",
      "run_pearson                             : BENCHMARK_1_GP_pearson\n",
      "run_single_drug_pearson                 : TEST_1_GP_single_drug_pearson\n",
      "run_single_drug_t_test                  : TEST_3_GP_single_drug_t_test\n",
      "run_t_test                              : BENCHMARK_5_GP_t_test\n",
      "\n",
      "Start Tests:\t Wed May 10, 2017 14:53 (31 s)\n"
     ]
    }
   ],
   "source": [
    "vt.view_dictionary(vt.GP_options)\n",
    "os.chdir(run_dir)\n",
    "os.system(\"make env_setup\")\n",
    "verification_root = os.path.abspath('../data/verification')\n",
    "resu_dir = os.path.abspath('run_dir/results')\n",
    "print('\\nStart Tests:\\t',time.strftime(\"%a %b %d, %Y %H:%M (%S s)\", time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run all small test methods and compare with verification BENCHMARK files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_4_GP_many_drugs_t_test \t run_multidrug_t_test\n",
      "TEST_3_GP_single_drug_t_test \t run_single_drug_t_test\n",
      "TEST_2_GP_many_drugs_pearson \t run_multidrug_pearson\n",
      "TEST_1_GP_single_drug_pearson \t run_single_drug_pearson\n",
      "BENCHMARK_8_GP_bootstrap_net_t_test \t run_bootstrap_net_t_test\n",
      "BENCHMARK_7_GP_net_t_test \t run_net_t_test\n",
      "BENCHMARK_6_GP_bootstrap_t_test \t run_bootstrap_t_test\n",
      "BENCHMARK_5_GP_t_test \t run_t_test\n",
      "BENCHMARK_4_GP_bootstrap_net_pearson \t run_bootstrap_net_pearson\n",
      "BENCHMARK_3_GP_net_pearson \t run_net_pearson\n",
      "BENCHMARK_2_GP_bootstrap_pearson \t run_bootstrap_pearson\n",
      "BENCHMARK_1_GP_pearson \t run_pearson\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yaml_methods_dict = {v: k for k, v in (vt.GP_options).items()}\n",
    "\n",
    "# rev_dict = {v: k for k, v in methods_verification_dict.items()}\n",
    "for y in sorted(yaml_methods_dict.keys(),reverse=True):\n",
    "    print(y,'\\t',yaml_methods_dict[y])\n",
    "    os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "    veri_dir = os.path.join(verification_root, y)\n",
    "    make_run_string = 'make' + ' ' + yaml_methods_dict[y]\n",
    "    os.system(make_run_string)\n",
    "    dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "    for k in sorted(dir_differ_dict.keys()):\n",
    "        if dir_differ_dict[k] != 0:\n",
    "            sum_of_all_differences += 1\n",
    "            print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run all small test methods and compare with verification BENCHMARK files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_single_drug_pearson\n",
    "veri_dir = os.path.join(verification_root, 'TEST_1_GP_single_drug_pearson')\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_single_drug_pearson\")\n",
    "\n",
    "print('Gene Prioritization TEST_1_GP_single_drug_pearson run in %0.2f seconds\\n'%(time.time() - t0))\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_multidrug_pearson\n",
    "veri_dir = os.path.join(verification_root, 'TEST_2_GP_many_drugs_pearson')\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_multidrug_pearson\")\n",
    "print('Gene Prioritization TEST_2_GP_many_drugs_pearson run in %0.2f seconds\\n'%(time.time() - t0))\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_single_drug_t_test\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_single_drug_t_test\")\n",
    "print('Gene Prioritization TEST_3_GP_single_drug_t_test run in %s seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'TEST_3_GP_single_drug_t_test')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_multidrug_t_test\n",
    "print('\\n\\t\\tNormal if Warnings are generated by this test: TEST_4_GP_many_drugs_t_test\\n')\n",
    "\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_multidrug_t_test\")\n",
    "print('Gene Prioritization TEST_4_GP_many_drugs_t_test run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dir = '../../Gene_Prioritization_Pipeline/data/verification/TEST_4_GP_many_drugs_t_test'\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run all Pearson Correlation methods and compare with verification BENCHMARK files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_pearson\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_pearson\")\n",
    "print('Gene Prioritization BENCHMARK_1_GP_pearson run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_1_GP_pearson')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_net_pearson\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_net_pearson\")\n",
    "print('Gene Prioritization BENCHMARK_3_GP_net_pearson run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_3_GP_net_pearson')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_bootstrap_pearson\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_bootstrap_pearson\")\n",
    "print('Gene Prioritization BENCHMARK_2_GP_bootstrap_pearson run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_2_GP_bootstrap_pearson')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_bootstrap_net_pearson\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "print(\"\\n\\t\\tNote that BENCHMARK_4_GP_bootstrap_net_pearson generates warnings\\n\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_bootstrap_net_pearson\")\n",
    "print('Gene Prioritization BENCHMARK_4_GP_bootstrap_net_pearson run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_4_GP_bootstrap_net_pearson')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run all t_test correlation methods and compare with verification BENCHMARK files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run t test\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_t_test\")\n",
    "print('Gene Prioritization BENCHMARK_5_GP_t_test run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_5_GP_t_test')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_bootstrap_t_test\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_bootstrap_t_test\")\n",
    "print('Gene Prioritization BENCHMARK_6_GP_bootstrap_t_test run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_6_GP_bootstrap_t_test')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_net_t_test\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_net_t_test\")\n",
    "print('Gene Prioritization BENCHMARK_7_GP_net_t_test run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_7_GP_net_t_test')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          run_bootstrap_net_t_test\n",
    "os.system(\"make clean_dir_recursively create_run_dir copy_run_files\")\n",
    "\n",
    "t0 = time.time()\n",
    "os.system(\"make run_bootstrap_net_t_test\")\n",
    "print('Gene Prioritization BENCHMARK_8_GP_bootstrap_net_t_test run in %0.2f seconds\\n'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dir = os.path.join(verification_root, 'BENCHMARK_8_GP_bootstrap_net_t_test')\n",
    "\n",
    "dir_differ_dict = vt.verification_directory_compare(veri_dir, resu_dir)\n",
    "for k in sorted(dir_differ_dict.keys()):\n",
    "    print(k, '\\t', dir_differ_dict[k], 'differences')\n",
    "    sum_of_all_differences = sum_of_all_differences + dir_differ_dict[k]\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = divmod(time.time() - t_start_test, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print('Gene Prioritization All tests run time:\\t%d:%02d:%02d'%(h, m, s))\n",
    "print('\\nFinished Tests:\\t',time.strftime(\"%a %b %d, %Y %H:%M (%S s)\", time.localtime()))\n",
    "print('Total number of differences = ', sum_of_all_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
