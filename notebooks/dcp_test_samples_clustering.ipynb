{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing KnowEnG-Research/Data_Cleanup_Pipeline Feb 27, 2017 (Samples Clustering)\n",
    "* for front end interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import knpackage.toolbox as kn\n",
    "import data_cleanup_toolbox as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples_clustering_run_parameters(yml_dir, yml_file_name):\n",
    "    \"\"\" run_parameters = get_samples_clustering_run_parameters(yml_dir, yml_file_name) \"\"\"\n",
    "    run_parameters = kn.get_run_parameters(yml_dir, yml_file_name)\n",
    "    run_parameters['results_directory'] = kn.create_dir(os.getcwd(), 'run_dir')\n",
    "    run_parameters['pipeline_type'] = 'samples_clustering_pipeline'\n",
    "    run_parameters['redis_credential']['host'] = 'knowhub.org'\n",
    "    run_parameters['redis_credential']['port'] = 6379\n",
    "    run_parameters['redis_credential']['password'] = 'KnowEnG'\n",
    "    \n",
    "    return run_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spreadsheets_for_pheno(pheno_file, sp_list):\n",
    "    \"\"\" spreadsheet_list = get_spreadsheets_for_pheno(pheno_file, sp_list) \"\"\"\n",
    "    x = pheno_file.find('.P.')\n",
    "    g_str = pheno_file[:x]\n",
    "    spreadsheet_list = []\n",
    "    for f in sp_list:\n",
    "        if f.find(g_str) >= 0: spreadsheet_list.append(f)\n",
    "\n",
    "    return sorted(spreadsheet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spreadsheet_phenotype_dataframe(spreadsheet_data_dir, pheno_data_dir):\n",
    "    \"\"\" test_result_df = get_spreadsheet_phenotype_dataframe(spreadsheet_data_dir, pheno_data_dir) \"\"\"\n",
    "    \n",
    "    col_list = ['phenotype_file','validation_flag','message','spreadsheet_rows','spreadsheet_cols','cleanup_time']\n",
    "    \n",
    "    pheno_file_list = sorted(os.listdir(pheno_data_dir))\n",
    "    spreadsheet_file_list = sorted(os.listdir(spreadsheet_data_dir))\n",
    "    \n",
    "    test_result_df = pd.DataFrame(data=np.zeros((len(spreadsheet_file_list), len(col_list))),\n",
    "                                  index=spreadsheet_file_list, columns=col_list)\n",
    "    \n",
    "    for pheno_file in pheno_file_list:\n",
    "        spreadsheet_list = get_spreadsheets_for_pheno(pheno_file, spreadsheet_file_list)\n",
    "        for spreadsheet_file in spreadsheet_list:\n",
    "            test_result_df.loc[spreadsheet_file, 'phenotype_file'] = pheno_file\n",
    "        \n",
    "    return test_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_samples_clustering_cleanup(run_parameters):\n",
    "    \"\"\" test_result_df = test_samples_clustering_cleanup(run_parameters) \"\"\"\n",
    "    \n",
    "    spreadsheet_data_dir = run_parameters['spreadsheet_data_dir']\n",
    "    pheno_data_dir = run_parameters['pheno_data_dir']\n",
    "    \n",
    "    test_result_df = get_spreadsheet_phenotype_dataframe(spreadsheet_data_dir, pheno_data_dir)\n",
    "    \n",
    "    for spreadsheet_file in list(test_result_df.index):\n",
    "        phenotype_file = test_result_df.loc[spreadsheet_file, 'phenotype_file']\n",
    "        if phenotype_file != 0:\n",
    "            print(phenotype_file, spreadsheet_file)\n",
    "            run_parameters['spreadsheet_name_full_path'] = os.path.join(spreadsheet_data_dir, spreadsheet_file)\n",
    "            run_parameters['phenotype_full_path'] = os.path.join(pheno_data_dir, phenotype_file)\n",
    "            \n",
    "            tt = 0.0\n",
    "            validation_flag = False\n",
    "            message = \"Failed to finish\"\n",
    "\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                #validation_flag, message = dc.run_samples_clustering_pipeline(run_parameters)\n",
    "                tt = time.time() - t0\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            test_result_df.loc[spreadsheet_file, 'message'] = message\n",
    "            test_result_df.loc[spreadsheet_file, 'cleanup_time'] = tt\n",
    "            test_result_df.loc[spreadsheet_file, 'validation_flag'] = validation_flag\n",
    "            \n",
    "    return test_result_df\n",
    "    # col_list = ['phenotype_file','validation_flag','message','spreadsheet_rows','spreadsheet_cols','cleanup_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lanier4/dlanier_KnowEnG/data_cleanup_pipeline_notebooks/Data_Cleanup_Pipeline/src'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/mnt/storage/interface/SC_G_spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pheno_data_dir :\t /Users/lanier4/pipeline_spreadsheets/aws_v3/SC_P_spreadsheets\n",
      "phenotype_full_path :\t ../data/spreadsheets/GDSC_drug_cpd_ic50_sample.tsv\n",
      "pipeline_type :\t samples_clustering_pipeline\n",
      "redis_credential :\t {'port': 6379, 'password': 'KnowEnG', 'host': 'knowhub.org'}\n",
      "results_directory :\t /Users/lanier4/dlanier_KnowEnG/data_cleanup_pipeline_notebooks/Data_Cleanup_Pipeline/src/run_dir1488313239854692\n",
      "run_directory :\t /Users/lanier4/dlanier_KnowEnG/data_cleanup_pipeline_notebooks/Data_Cleanup_Pipeline/src\n",
      "run_file :\t Feb_27_test.yml\n",
      "source_hint :\t \n",
      "spreadsheet_data_dir :\t /Users/lanier4/pipeline_spreadsheets/aws_v3/SC_G_spreadsheets\n",
      "spreadsheet_name_full_path :\t ../data/spreadsheets/GDSC_Expression_ensembl.tsv\n",
      "taxonid :\t 9606\n"
     ]
    }
   ],
   "source": [
    "yml_file_name = 'Feb_27_test.yml'\n",
    "yml_dir = os.getcwd()\n",
    "run_parameters = get_samples_clustering_run_parameters(yml_dir, yml_file_name)\n",
    "\n",
    "run_parameters['spreadsheet_data_dir'] = '/Users/lanier4/pipeline_spreadsheets/aws_v3/SC_G_spreadsheets'\n",
    "run_parameters['pheno_data_dir'] = '/Users/lanier4/pipeline_spreadsheets/aws_v3/SC_P_spreadsheets'\n",
    "\n",
    "for k in sorted(run_parameters.keys()):\n",
    "    print(k,':\\t',run_parameters[k])\n",
    "\n",
    "# pheno_data_dir = '/Users/lanier4/pipeline_spreadsheets/aws_v3/SC_P_spreadsheets'\n",
    "# spreadsheet_data_dir = '/Users/lanier4/pipeline_spreadsheets/aws_v3/SC_G_spreadsheets'\n",
    "# pheno_dict, spreadsheet_file_list = get_pheno_spreadsheet_dict(spreadsheet_data_dir, pheno_data_dir)\n",
    "# test_result_df = get_spreadsheet_phenotype_dataframe(spreadsheet_data_dir, pheno_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hsap.ccle.P.cyto_ic50.pos.c.df Hsap.ccle.G.gene_mut.binary.a.df\n",
      "Hsap.ccle.P.cyto_ic50.pos.c.df Hsap.ccle.G.lg2_cn_ratio.real.a.df\n",
      "Hsap.ccle.P.cyto_ic50.pos.c.df Hsap.ccle.G.qnorm_probe.pos.a.df\n",
      "Hsap.dream11.P.cell_line_info.mixed.c.df Hsap.dream11.G.exome_mut.binary.a.df\n",
      "Hsap.dream11.P.cell_line_info.mixed.c.df Hsap.dream11.G.gene_cn.pos.a.df\n",
      "Hsap.dream11.P.cell_line_info.mixed.c.df Hsap.dream11.G.probe_expr.pos.a.df\n",
      "Hsap.dream7_c1.P.cyto_gi50.pos.c.df Hsap.dream7_c1.G.lg2_cnv.real.a.df\n",
      "Hsap.dream7_c1.P.cyto_gi50.pos.c.df Hsap.dream7_c1.G.lg2_probe.pos.a.df\n",
      "Hsap.dream7_c1.P.cyto_gi50.pos.c.df Hsap.dream7_c1.G.methyl_prop.pos.a.df\n",
      "Hsap.dream7_c1.P.cyto_gi50.pos.c.df Hsap.dream7_c1.G.rnaseq_expressed.binary.a.df\n",
      "Hsap.dream7_c1.P.cyto_gi50.pos.c.df Hsap.dream7_c1.G.rnaseq_fpkm.pos.a.df\n",
      "Hsap.gdsc.P.norm_ic50.real.c.df Hsap.gdsc.G.probe_expr.pos.a.df\n",
      "Hsap.mayo_lcl.P.cyto_ec50.pos.c.df Hsap.mayo_lcl.G.med_lg2_norm_probe.real.a.df\n",
      "Hsap.mayo_lcl.P.cyto_ec50.pos.c.df Hsap.mayo_lcl.G.norm_reg_snp_ct.real.a.df\n",
      "Hsap.nbs_LUAD.P.clinical.mixed.c.df Hsap.nbs_LUAD.G.gene_som_mut.binary.a.df\n",
      "Hsap.nbs_OV.P.clinical.mixed.c.df Hsap.nbs_OV.G.gene_som_mut.binary.a.df\n",
      "Hsap.nbs_UCEC.P.clinical.mixed.c.df Hsap.nbs_UCEC.G.gene_som_mut.binary.a.df\n",
      "Hsap.ovarian.P.clinical.mixed.c.df Hsap.ovarian.G.lm_corr_expr.real.a.df\n",
      "Hsap.tcga_cgc.P.clinical.mixed.c.df Hsap.tcga_cgc.G.rpkm.pos.a.df\n",
      "Hsap.tcga_ucsc.P.clinical.mixed.c.df Hsap.tcga_ucsc.G.som_mut.binary.a.df\n"
     ]
    }
   ],
   "source": [
    "test_result_df = test_samples_clustering_cleanup(run_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hsap.ccle.P.cell_line_info.mixed.c.df\n",
      "\t Hsap.ccle.G.gene_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.ccle.G.lg2_cn_ratio.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.ccle.G.qnorm_probe.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.ccle.P.cyto_ec50.pos.c.df\n",
      "\t Hsap.ccle.G.gene_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.ccle.G.lg2_cn_ratio.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.ccle.G.qnorm_probe.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.ccle.P.cyto_ic50.pos.c.df\n",
      "\t Hsap.ccle.G.gene_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.ccle.G.lg2_cn_ratio.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.ccle.G.qnorm_probe.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.dream11.P.avg_ic50.pos.c.df\n",
      "\t Hsap.dream11.G.exome_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream11.G.gene_cn.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream11.G.probe_expr.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.dream11.P.cell_line_info.mixed.c.df\n",
      "\t Hsap.dream11.G.exome_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream11.G.gene_cn.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream11.G.probe_expr.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.dream7_c1.P.cyto_gi50.pos.c.df\n",
      "\t Hsap.dream7_c1.G.lg2_cnv.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream7_c1.G.lg2_probe.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream7_c1.G.methyl_prop.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream7_c1.G.rnaseq_expressed.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.dream7_c1.G.rnaseq_fpkm.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.gdsc.P.norm_ic50.real.c.df\n",
      "\t Hsap.gdsc.G.probe_expr.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.lincs_drug_prostate.P.experimental.mixed.c.df\n",
      "\n",
      " Hsap.mayo_lcl.P.clinical.mixed.c.df\n",
      "\t Hsap.mayo_lcl.G.med_lg2_norm_probe.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.mayo_lcl.G.norm_reg_snp_ct.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.mayo_lcl.P.cyto_auc.pos.c.df\n",
      "\t Hsap.mayo_lcl.G.med_lg2_norm_probe.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.mayo_lcl.G.norm_reg_snp_ct.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.mayo_lcl.P.cyto_ec50.pos.c.df\n",
      "\t Hsap.mayo_lcl.G.med_lg2_norm_probe.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\t Hsap.mayo_lcl.G.norm_reg_snp_ct.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.nbs_LUAD.P.clinical.mixed.c.df\n",
      "\t Hsap.nbs_LUAD.G.gene_som_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.nbs_OV.P.clinical.mixed.c.df\n",
      "\t Hsap.nbs_OV.G.gene_som_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.nbs_UCEC.P.clinical.mixed.c.df\n",
      "\t Hsap.nbs_UCEC.G.gene_som_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.ovarian.P.clinical.mixed.c.df\n",
      "\t Hsap.ovarian.G.lm_corr_expr.real.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.tcga_cgc.P.clinical.mixed.c.df\n",
      "\t Hsap.tcga_cgc.G.rpkm.pos.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "\n",
      " Hsap.tcga_ucsc.P.clinical.mixed.c.df\n",
      "\t Hsap.tcga_ucsc.G.som_mut.binary.a.df\n",
      "\t\tFalse in 0.000\n",
      "\t\tfailed in try block\n",
      "total testing time = 0.00\n",
      "spreadsheet files that CRASHED cleanup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_flag = False\n",
    "tt = 0.0\n",
    "message = 'failed in try block'\n",
    "\n",
    "failed_cleanup = []\n",
    "t_00 = time.time()\n",
    "for pheno_file in sorted(pheno_dict.keys()):\n",
    "    print('\\n',pheno_file)\n",
    "    run_parameters['phenotype_full_path'] = os.path.join(pheno_data_dir, pheno_file)\n",
    "    for k in range(0,len(pheno_dict[pheno_file])):\n",
    "        sp_file_name = pheno_dict[pheno_file][k]\n",
    "        print('\\t', sp_file_name)\n",
    "        run_parameters['spreadsheet_name_full_path'] = os.path.join(spreadsheet_data_dir, sp_file_name)\n",
    "\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            # validation_flag, message = dc.run_samples_clustering_pipeline(run_parameters)\n",
    "            tt = time.time() - t0\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        passed_test = \"False\"\n",
    "        if failed_cleanup:\n",
    "            print('\\t\\t%s crashed the cleanup code !!!'%sp_file_name)\n",
    "            failed_cleanup.append(sp_file_name)\n",
    "        else:\n",
    "            if validation_flag: passed_test = \"True\"\n",
    "\n",
    "        print('\\t\\t%s in %0.3f\\n\\t\\t%s'%(passed_test, tt, message))\n",
    "\n",
    "print('total testing time = %0.2f'%(time.time() - t_00))\n",
    "print('spreadsheet files that CRASHED cleanup')\n",
    "failed_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hsap.ccle.P.cell_line_info.mixed.c.df\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pheno_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c99585a11921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpheno_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrun_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phenotype_full_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpheno_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpheno_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpheno_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msp_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpheno_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pheno_file' is not defined"
     ]
    }
   ],
   "source": [
    "validation_flag = False\n",
    "tt = 0.0\n",
    "message = 'failed in try block'\n",
    "\n",
    "failed_cleanup = []\n",
    "t_00 = time.time()\n",
    "for key_k in sorted(pheno_dict.keys()):\n",
    "    print('\\n',key_k)\n",
    "    run_parameters['phenotype_full_path'] = os.path.join(pheno_data_dir, pheno_file)\n",
    "    for k in range(0,len(pheno_dict[key_k])):\n",
    "        sp_file_name = pheno_dict[key_k][k]\n",
    "        print('\\t', sp_file_name)\n",
    "        run_parameters['spreadsheet_name_full_path'] = os.path.join(spreadsheet_data_dir, sp_file_name)\n",
    "\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            # validation_flag, message = dc.run_samples_clustering_pipeline(run_parameters)\n",
    "            tt = time.time() - t0\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        passed_test = \"False\"\n",
    "        if failed_cleanup:\n",
    "            print('\\t\\t%s crashed the cleanup code !!!'%sp_file_name)\n",
    "            failed_cleanup.append(sp_file_name)\n",
    "        else:\n",
    "            if validation_flag: passed_test = \"True\"\n",
    "\n",
    "        print('\\t\\t%s in %0.3f\\n\\t\\t%s'%(passed_test, tt, message))\n",
    "\n",
    "print('total testing time = %0.2f'%(time.time() - t_00))\n",
    "print('spreadsheet files that CRASHED cleanup')\n",
    "failed_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pheno_df = pd.read_csv(os.path.join(pheno_data_dir, \n",
    "                                    'Hsap.ccle.P.cell_line_info.mixed.c.df'), sep='\\t', header=0, index_col=0)\n",
    "spreadsheet_df = pd.read_csv(os.path.join(spreadsheet_data_dir, \n",
    "                                    'Hsap.ccle.G.gene_mut.binary.a.df'), sep='\\t', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_rows = list(pheno_df.index)\n",
    "spreadsheet_cols = list(spreadsheet_df.columns)\n",
    "pheno_spreadsheet_intersect = list(set(spreadsheet_cols) & set(pheno_rows))\n",
    "print('number of members:\\npheno_rows\\t%d\\nspreadsheet_cols\\t%d\\npheno_spreadsheet_intersect\\t%d'%(\n",
    "        len(pheno_rows), len(spreadsheet_cols), len(pheno_spreadsheet_intersect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spreadsheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_input_data_as_df(spreadsheet_path, phenotype_path=None):\n",
    "    \"\"\"\n",
    "    Reads two input data: user spreadsheet and phenotype data(optional)\n",
    "\n",
    "    Args:\n",
    "        spreadsheet_path: full path of user spreadsheet\n",
    "        phenotype_path: full path of phenotype data\n",
    "\n",
    "    Returns:\n",
    "        user_spreadsheet_df: user spreadsheet as data frame\n",
    "        phenotype_df: phenotype data as data frame\n",
    "    \"\"\"\n",
    "    user_spreadsheet_df = load_data_file(spreadsheet_path)\n",
    "    phenotype_df = None if phenotype_path is None else load_data_file(phenotype_path)\n",
    "\n",
    "    return user_spreadsheet_df, phenotype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_input_value_for_samples_clustering(data_frame, run_parameters, phenotype_df=None):\n",
    "    \"\"\"\n",
    "    Checks if the values in user spreadsheet matches with golden standard value set\n",
    "        and rename phenotype file to have suffix _ETL.tsv\n",
    "\n",
    "    Args:\n",
    "        data_frame: input data frame\n",
    "        phenotype_df: input phenotype data frame\n",
    "        golden_value_set: golden standard value set to be compared with\n",
    "\n",
    "    Returns:\n",
    "        data_frame: processed data_frame\n",
    "        message: A message indicates the status of current check\n",
    "    \"\"\"\n",
    "    if data_frame.isnull().values.any():\n",
    "        return None, \"This user spreadsheet contains invalid NaN value.\"\n",
    "\n",
    "    # checks if it contains only real number\n",
    "    data_frame_real_number = data_frame.applymap(lambda x: isinstance(x, (int, float)))\n",
    "\n",
    "    if False in data_frame_real_number.values:\n",
    "        return None, \"Found non-numeric value in user spreadsheet.\"\n",
    "\n",
    "    # checks if it contains only positive number\n",
    "    data_frame_abs = data_frame.abs()\n",
    "\n",
    "    return data_frame_abs, \"Value contains in user spreadsheet matches with golden standard value set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check_user_spreadsheet(user_spreadsheet_df, run_parameters):\n",
    "    \"\"\"\n",
    "    Checks the validity of user input spreadsheet data file\n",
    "\n",
    "    Args:\n",
    "        user_spreadsheet_df: user spreadsheet input file data frame, which is uploaded from frontend\n",
    "        run_parameters: run_file parameter dictionary\n",
    "\n",
    "    Returns:\n",
    "        flag: Boolean value indicates the status of current check\n",
    "        message: A message indicates the status of current check\n",
    "    \"\"\"\n",
    "    print('sanity_check_user_spreadsheet called with user_spreadsheet_df.shape', user_spreadsheet_df.shape)\n",
    "    \n",
    "    # Case 1: checks the duplication on column name and removes it if exists\n",
    "    user_spreadsheet_df_col_dedup, error_msg = check_duplicate_column_name(user_spreadsheet_df)\n",
    "    if user_spreadsheet_df_col_dedup is None:\n",
    "        return None, error_msg\n",
    "\n",
    "    # Case 2: checks the duplication on gene name and removes it if exists\n",
    "    user_spreadsheet_df_genename_dedup, error_msg = check_duplicate_row_name(user_spreadsheet_df_col_dedup)\n",
    "    if user_spreadsheet_df_genename_dedup is None:\n",
    "        return None, error_msg\n",
    "\n",
    "    # Case 3: checks the validity of gene name meaning if it can be ensemble or not\n",
    "    user_spreadsheet_df_final, error_msg = check_ensemble_gene_name(user_spreadsheet_df_genename_dedup, run_parameters)\n",
    "\n",
    "    return user_spreadsheet_df_final, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_duplicate_column_name(data_frame):\n",
    "    \"\"\"\n",
    "    Checks duplicate column names and rejects it if it exists\n",
    "\n",
    "    Args: data_frame:\n",
    "    Returns:\n",
    "        user_spreadsheet_df_genename_dedup.T: a data frame in original format\n",
    "        error_msg: error message\n",
    "    \"\"\"\n",
    "    data_frame_transpose = data_frame.T\n",
    "    user_spreadsheet_df_genename_dedup, error_msg = check_duplicate_row_name(data_frame_transpose)\n",
    "\n",
    "    if user_spreadsheet_df_genename_dedup is None:\n",
    "        return False, error_msg\n",
    "\n",
    "    return user_spreadsheet_df_genename_dedup.T, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_duplicate_row_name(data_frame):\n",
    "    \"\"\"\n",
    "    Checks duplication on gene name and rejects it if it exists\n",
    "\n",
    "    Args:\n",
    "        data_frame: input data frame\n",
    "\n",
    "    Returns:\n",
    "        data_frame_genename_dedup: a data frame in original format\n",
    "        error_msg: error message\n",
    "    \"\"\"\n",
    "    data_frame_genename_dedup = data_frame[~data_frame.index.duplicated()]\n",
    "    row_count_diff = len(data_frame.index) - len(data_frame_genename_dedup.index)\n",
    "\n",
    "    if row_count_diff > 0:\n",
    "        return data_frame_genename_dedup, \"Found duplicate gene names \" \\\n",
    "                                          \"and dropped these duplicates. \"\n",
    "\n",
    "    if row_count_diff == 0:\n",
    "        return data_frame_genename_dedup, \"No duplication detected in this data set.\"\n",
    "\n",
    "    return None, \"An unexpected error occurred during checking duplicate row name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_ensemble_gene_name(data_frame, run_parameters):\n",
    "    \"\"\"\n",
    "    Checks if the gene name follows ensemble format.\n",
    "\n",
    "    Args:\n",
    "        data_frame: input data frame\n",
    "        run_parameters: user configuration from run_file\n",
    "\n",
    "    Returns:\n",
    "         match_flag: Boolean value indicates the status of current check\n",
    "         message: A message indicates the current status of current check\n",
    "    \"\"\"\n",
    "    redis_db = redisutil.get_database(run_parameters['redis_credential'])\n",
    "\n",
    "    data_frame['original'] = data_frame.index\n",
    "\n",
    "    data_frame.index = data_frame.index.map(\n",
    "        lambda x: redisutil.conv_gene(redis_db, x, run_parameters['source_hint'], run_parameters['taxonid']))\n",
    "\n",
    "    # extracts all mapped rows in dataframe\n",
    "    output_df_mapped = data_frame[~data_frame.index.str.contains(r'^unmapped.*$')]\n",
    "    output_df_mapped = output_df_mapped.drop('original', axis=1)\n",
    "\n",
    "    # dedup on gene name mapping dictionary\n",
    "    mapping = data_frame[['original']]\n",
    "\n",
    "    mapping_filtered = mapping[~mapping.index.str.contains(r'^unmapped.*$')]\n",
    "\n",
    "    unmapped_filtered = mapping[mapping.index.str.contains(r'^unmapped.*$')].sort_index(axis=0, ascending=False)\n",
    "    unmapped_filtered['ensemble'] = unmapped_filtered.index\n",
    "\n",
    "    mapping_dedup_df = mapping_filtered[~mapping_filtered.index.duplicated()]\n",
    "\n",
    "    output_file_basename = get_file_basename(run_parameters['spreadsheet_name_full_path'])\n",
    "\n",
    "    # writes unmapped gene name along with return value from Redis database to a file\n",
    "    unmapped_filtered.to_csv(run_parameters['results_directory'] + '/' + output_file_basename + \"_UNMAPPED.tsv\",\n",
    "                             sep='\\t', header=False, index=False)\n",
    "\n",
    "    # writes dedupped mapping between original gene name and ensemble name to a file\n",
    "    mapping_dedup_df.to_csv(run_parameters['results_directory'] + '/' + output_file_basename + \"_MAP.tsv\",\n",
    "                            sep='\\t', header=False, index=True)\n",
    "\n",
    "    if output_df_mapped.empty:\n",
    "        return None, \"No valid ensemble name can be found.\"\n",
    "\n",
    "    return output_df_mapped, \"This is a valid user spreadsheet. Proceed to next step analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_samples_clustering_pipeline(run_parameters):\n",
    "    \"\"\"\n",
    "    Runs data cleaning for samples_clustering_pipeline.\n",
    "\n",
    "    Args:\n",
    "        run_parameters: configuration dictionary\n",
    "\n",
    "    Returns:\n",
    "        validation_flag: Boolean type value indicating if input data is valid or not\n",
    "        message: A message indicates the status of current check\n",
    "    \"\"\"\n",
    "    if 'phenotype_full_path' in run_parameters and run_parameters['phenotype_full_path']:\n",
    "        user_spreadsheet_df, phenotype_df = read_input_data_as_df(run_parameters['spreadsheet_name_full_path'],\n",
    "                                                                  run_parameters['phenotype_full_path'])\n",
    "    else:\n",
    "        user_spreadsheet_df, phenotype_df = read_input_data_as_df(run_parameters['spreadsheet_name_full_path'])\n",
    "\n",
    "    # Value check logic a: checks if only 0 and 1 appears in user spreadsheet and rename phenotype data file to have _ETL.tsv suffix\n",
    "    user_spreadsheet_val_chked, error_msg = check_input_value_for_samples_clustering(user_spreadsheet_df,\n",
    "                                                                                     run_parameters,\n",
    "                                                                                     phenotype_df)\n",
    "\n",
    "    if user_spreadsheet_val_chked is None:\n",
    "        return False, error_msg\n",
    "\n",
    "    # Other checks including duplicate column/row name check and gene name to ensemble name mapping check\n",
    "    user_spreadsheet_df_cleaned, error_msg = sanity_check_user_spreadsheet(user_spreadsheet_val_chked, run_parameters)\n",
    "\n",
    "    if user_spreadsheet_df_cleaned is None:\n",
    "        return False, error_msg\n",
    "    else:\n",
    "        if phenotype_df is not None and not phenotype_df.empty:\n",
    "            phenotype_df.to_csv(run_parameters['results_directory'] + '/' + get_file_basename(\n",
    "                run_parameters['phenotype_full_path']) + \"_ETL.tsv\",\n",
    "                                sep='\\t', header=True, index=True)\n",
    "\n",
    "        user_spreadsheet_df_cleaned.to_csv(run_parameters['results_directory'] + '/' + get_file_basename(\n",
    "            run_parameters['spreadsheet_name_full_path']) + \"_ETL.tsv\",\n",
    "                                sep='\\t', header=True, index=True)\n",
    "    \n",
    "    return True, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_pheno_and_spreadsheets(data_dir):\n",
    "#     \"\"\" sp_list, pheno_list = get_pheno_and_spreadsheets(data_dir)  \"\"\"\n",
    "#     dir_file_list = os.listdir(data_dir)\n",
    "#     pheno_list = []\n",
    "#     sp_list = []\n",
    "#     for f in dir_file_list:\n",
    "#         if f.find('.P.') > 0: pheno_list.append(f)\n",
    "#         if f.find('.G.') > 0: sp_list.append(f)\n",
    "#     return sp_list, pheno_list"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
